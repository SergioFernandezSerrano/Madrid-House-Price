---
title: "Madrid House Price"
author: "Sergio Fernández, Miguel Ocón, Enrique Roa"
date: "`r format(Sys.Date(), '%d de %B de %Y')`"
output:
  html_document:
    code_folding: hide
    theme: flatly
    number_sections: yes
    toc: yes
    toc_depth: 2
    toc_float: yes
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	include = TRUE,
	warning = FALSE,
	message = FALSE,
	fig.align = "center",
	out.width = "90%"
)
```

![](Gran_Vía_(Madrid)_1.jpg)

# Introducción y definición de objetivos

El análisis de datos en el mercado inmobiliario es algo muy común y que lleva muchísimos años  desarrollándose. Con el objetivo de predecir que aspectos influyen principalmente en el precio de las casas en Madrid, hemos seleccionado un dataset  ([kaggle - Madrid House Price](https://www.kaggle.com/datasets/kevsde/madrid-house-price)) con viviendas en venta de la capital española.

```{r}
library(readr)
library(dplyr)
library(tidyr)
library(kableExtra)
library(ggplot2)
library(cowplot)
library(ggcorrplot)
library(gmodels)
library(caret)
library(ggfortify)
library(scales)
library(cluster)
library(tidyverse)
library(stringr)
library(ggfortify)
library(caret)
library(Metrics)
library(factoextra)
library(NbClust)
```

```{r}
paste(R.Version()$version.string)
```
# Análisis exploratorio inicial

## Lectura y preparación de los datos

En esta primera etapa cargamos el dataset descargado y hacemos una observación superficial de las variables recogidas y sus características. Se representan también las 10 filas iniciales.

```{r}
mhp <- read_csv("house_price_madrid_14_08_2022.csv")
```

```{r}
head(mhp, 10) %>%
  kbl() %>%
  kable_material(c("striped", "hover")) %>%
  scroll_box(width = "100%", height = "350px")
```

```{r}
summary(mhp)
```

```{r}
str(mhp) 
```

El dataset contiene **15.975 observaciones** (correspondientes a una vivienda cada una) y **9 variables** (de las cuales son **6 cualitativas** y **3 cuantitativas**).

A continuación, la descripción de cada una de las variables:

  - **price**: precio
  
  - **house_type**: tipo de vivienda (casa, chalet, piso...)
  
  - **house_type_2**: si es exterior o interior
  
  - **rooms**: número de habitaciones
  
  - **m2**: metros cuadrados
  
  - **elevator**: si tiene ascensor
  
  - **garage**: si incluye garaje
  
  - **neighborhood**: barrio de Madrid
  
  - **district**: distrito de Madrid

Tras esta primera observación se harán algunas modificaciones en el dataset para transformar a variables de tipo categórico las que correspondan, así como transformar a binarias (1/0) aquellas con sólo dos valores posibles.

```{r}
# Preparación de los datos. Convertimos a factores las variables que son categóricas y a 1-0 las binarias.

mhp <- mhp %>% rename(exterior = house_type_2)
mhp$exterior = ifelse(mhp$exterior == "exterior", 1, 0)
mhp$exterior = factor(mhp$exterior, levels = c(1,0))

mhp$elevator = ifelse(mhp$elevator == "TRUE", 1, 0)
mhp$elevator = factor(mhp$elevator, levels = c(1,0))

mhp$garage = ifelse(mhp$garage == "TRUE", 1, 0)
mhp$garage = factor(mhp$garage, levels = c(1,0))

mhp$house_type <- as.factor(mhp$house_type)
mhp$exterior <- as.factor(mhp$exterior)
mhp$elevator <- as.factor(mhp$elevator)
mhp$garage <- as.factor(mhp$garage)
mhp$neighborhood <- as.factor(mhp$neighborhood)
mhp$district <- as.factor(mhp$district)
```

## Tratamiento de datos faltantes

Convertimos en NA aquellas observaciones que claramente contienen algun error:

  - La casa de 41 habitaciones (probablemente fueran 4 y esté mal imputado)
  
  - Las que tienen menos de 3 m2 (probablemente mal imputados al usar el punto para separar los miles)
  
  - La casa con un precio de 725 (claramente equivocado).

```{r}
mhp$rooms[mhp$rooms > 40] <- NA
mhp$m2[mhp$m2 < 3] <- NA
mhp$price[mhp$price < 1000] <- NA
```

Por otro lado, la variable **house_type_2** tiene 469 filas sin datos. Junto a los NA añadidos en el paso anterior son el 3.2% del total, por lo que optaremos por eliminar estas filas del dataset.

```{r}
sum(is.na(mhp))/nrow(mhp)
mhp <- na.omit(mhp)
```

## División del dataset

Para finalizar la preparación de los datos, dividiremos nuestro dataset en tres partes, una de entrenamiento (train), con el que trabajaremos durante todo el análisis, otra de prueba (test) que nos servirá para comprobar la eficacia de los diferentes modelos predictivos que se apliquen, y finalmente uno de validación (validation), que se mantendrá sin usar hasta el último día del proyecto y con el cual validaremos el modelo final.

```{r}
set.seed(108)
numero_total = nrow(mhp)
# Porcentajes de train, test y validation
w_train = .5
w_test = .25
w_validation = 1 - (w_train + w_test)

# Todos los índices
indices = seq(1:numero_total) 

# Muestreo
indices_train = sample(1:numero_total, numero_total * w_train)
indices_test = sample(indices[-indices_train], numero_total * w_test)
indices_validation = indices[-c(indices_train,indices_test)]

# Agrupamos

mhp_train = mhp[indices_train,]
mhp_test = mhp[indices_test,]
mhp_validation = mhp[indices_validation,]
```

# Análisis univariante

## Análisis de variables cualitativas

Una vez preparado el dataset comenzamos con el análisis de las variables cualitativas, que son las siguientes:

**Tipo de vivienda**

```{r}
merge(setNames(as.data.frame(table(mhp_train$house_type)), c("house_type", "count")),
      setNames(as.data.frame(round(prop.table(table(mhp_train$house_type))*100, 2)), c("house_type", "prop (%)"))
) %>%
  arrange(desc(count)) %>%
  kbl() %>%
  kable_material(c("striped", "hover")) %>%
  scroll_box(width = "100%", height = "350px")
```

```{r}
ggplot(mhp_train, aes(house_type)) +
  geom_bar(fill = "#0BB363") +
  coord_flip() +
  labs(x = "Tipo de vivienda", y = "Número de viviendas", title = "Viviendas por tipo") +
  theme(plot.title = element_text(hjust = 0.5))
```

Como era de esperar, las viviendas más habituales son pisos en plantas no demasiado altas (bajos, primeros, segundos...). El número de casas y chalets también es pequeño en proporción.

**Orientación exterior**

```{r}
merge(setNames(as.data.frame(table(mhp_train$exterior)), c("exterior", "count")),
      setNames(as.data.frame(round(prop.table(table(mhp_train$exterior))*100, 2)), c("exterior", "prop (%)"))
) %>%
  kbl() %>%
  kable_material(c("striped", "hover"))
```

```{r}
ggplot(mhp_train, aes(exterior)) +
  geom_bar(fill = "#0BB363") +
  labs(x = "Exterior", y = "Número de vivienda de viviendas", title = "Viviendas exteriores") +
  theme(plot.title = element_text(hjust = 0.5))
```

Son una inmensa mayoría los pisos que dan a exterior.

**Ascensor**

```{r}
merge(setNames(as.data.frame(table(mhp_train$elevator)), c("elevator", "count")),
      setNames(as.data.frame(round(prop.table(table(mhp_train$elevator))*100, 2)), c("elevator", "prop (%)"))
) %>%
  kbl() %>%
  kable_material(c("striped", "hover"))
```

```{r}
ggplot(mhp_train, aes(elevator)) +
  geom_bar(fill = "#0BB363") +
  labs(x = "Ascensor", y = "Número de viviendas", title = "Viviendas con ascensor") +
  theme(plot.title = element_text(hjust = 0.5))
```

También es más frecuente que tengan ascensor, aunque casi el 30% no lo tienen.

**Garaje**

```{r}
merge(setNames(as.data.frame(table(mhp_train$garage)), c("garage", "count")),
      setNames(as.data.frame(round(prop.table(table(mhp_train$garage))*100, 2)), c("garage", "prop (%)"))
) %>%
  kbl() %>%
  kable_material(c("striped", "hover"))
```

```{r}
ggplot(mhp_train, aes(garage)) +
  geom_bar(fill = "#0BB363") +
  labs(x = "Garaje", y = "Número de viviendas", title = "Viviendas con garaje") +
  theme(plot.title = element_text(hjust = 0.5))
```

También de esperar que la mayoría de pisos no tuvieran garaje incluido.

**Barrio**

Esta variable no será muy útil para el análisis, ya que en muchos casos son descripciones de la vivienda hechas por el usuario, por lo que habría que hacer un tratamiento previo para poder agruparlas. Algo innecesario ya que ese mismo efecto se consigue con el siguiente campo: distritos.

```{r}
merge(setNames(as.data.frame(table(mhp_train$neighborhood)), c("neighborhood", "count")),
      setNames(as.data.frame(round(prop.table(table(mhp_train$neighborhood))*100, 2)), c("neighborhood", "prop (%)"))
) %>%
  kbl() %>%
  kable_material(c("striped", "hover")) %>%
  scroll_box(width = "100%", height = "350px")
```

**Distrito**

En este caso los datos si están correctamente recogidos, repartiendo las casas entre los 21 distritos de Madrid.Casi todos con una representación considerable, en lo que destaca el barrio de Salamanca, con casi el doble de viviendas que el segundo que más tiene, Chamberí.

```{r}
merge(setNames(as.data.frame(table(mhp_train$district)), c("district", "count")),
      setNames(as.data.frame(round(prop.table(table(mhp_train$district))*100, 2)), c("district", "prop (%)"))
) %>%
  arrange(desc(count)) %>%
  kbl() %>%
  kable_material(c("striped", "hover")) %>%
  scroll_box(width = "100%", height = "350px")
```

```{r}
ggplot(mhp_train, aes(district)) +
  geom_bar(fill = "#0BB363") +
  labs(x = "Distrito", y = "Número de viviendas", title = "Viviendas por distrito") +
  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 30, hjust = 1))
```

## Análisis de variables cuantitativas

**Precio**

```{r}
data.frame(summarise(mhp_train,
                     min = min(price),
                     max = max(price),
                     median = median(price),
                     mean = mean(price),
                     sd = sd(price))) %>%
  kbl() %>%
  kable_material(c("striped", "hover"))
```

```{r}
ggplot(mhp_train, aes(y = price)) +
  geom_boxplot(fill = "#0BB363") +
  labs(y = "Precio", title = "Boxplot de precios") +
  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 30, hjust = 1))
```

```{r}
ggplot(mhp_train, aes(price)) +
  geom_histogram(aes(y=..density..), bins = 50, position = "dodge", fill = "#0BB363") +
  geom_density(alpha=.2, fill = "red") +
  labs(x = "Precio", y = "Número de viviendas", title = "Viviendas por Precio") +
  scale_x_continuous(breaks = pretty(mhp_train$price, n = 10),labels = comma_format()) +
  scale_y_continuous(labels = comma_format()) +
  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 30))
```

**Habitaciones**

```{r}
data.frame(summarise(mhp_train,
                     min = min(rooms),
                     max = max(rooms),
                     median = median(rooms),
                     mean = mean(rooms),
                     sd = sd(rooms))) %>%
  kbl() %>%
  kable_material(c("striped", "hover"))
```

```{r}
ggplot(mhp_train, aes(y = rooms)) +
  geom_boxplot(fill = "#0BB363") +
  labs(y = "Habitaciones", title = "Boxplot de habitaciones") +
  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 30, hjust = 1))
```

```{r}
ggplot(mhp_train, aes(rooms)) +
  geom_histogram(aes(), bins = 16, position = "dodge", fill = "#0BB363") +
  geom_density(alpha=.2, fill = "red") +
  labs(x = "Habitaciones", y = "Número de viviendas", title = "Viviendas por número de habitaciones") +
  theme(plot.title = element_text(hjust = 0.5))
```

**m²**

```{r}
data.frame(summarise(mhp_train,
                     min = min(m2),
                     max = max(m2),
                     median = median(m2),
                     mean = mean(m2),
                     sd = sd(m2))) %>%
  kbl() %>%
  kable_material(c("striped", "hover"))
```

```{r}
ggplot(mhp_train, aes(y = m2)) +
  geom_boxplot(fill = "#0BB363") +
  labs(y = "Metros cuadrados", title = "Boxplot de superficies") +
  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 30, hjust = 1))
```

```{r}
ggplot(mhp_train, aes(m2)) +
  geom_histogram(aes(y=..density..), bins = 50, position = "dodge", fill = "#0BB363") +
  geom_density(alpha=.5, fill = "red") +
  labs(x = "Metros cuadrados", y = "Número de viviendas", title = "Viviendas por metros cuadrados") +
  theme(plot.title = element_text(hjust = 0.5))
```

# Análisis multivariante

Una vez analizadas todas las variables de forma individual, podemos buscar algunas relaciones entre ellas.

Como se ve en los gráficos inferiores hay una relción fuerte entre el precio, los metros cuadradados y el número de habitaciones.

```{r}
plot_grid(
  ggcorrplot(cor(mhp_train %>% select_if(is.numeric)),type = "lower", lab=TRUE),
  
  ggplot(mhp_train, aes(x = m2, y = price)) +
  geom_point() +
  geom_smooth() +
  ggtitle('Relación entre el precio y los metros cuadrados'),
  
  ggplot(mhp_train, aes(x = rooms, y = price)) +
  geom_point() +
  geom_smooth() +
  ggtitle('Relación entre el precio y el número de habitaciones'),
  
  ggplot(mhp_train, aes(x = rooms, y = m2)) +
  geom_point() +
  geom_smooth() +
  ggtitle('Relación entre los metros cuadrados y el número de habitaciones'),
  
  nrow = 2
)
```

Introduciendo algunas de las variables categóricas se puede observar como varía el precio con la superficie o el número de habitaciones dependiendo de si incluye garaje, ascensor u orientación exterior.

```{r}
plot_grid(
  ggplot(mhp_train, aes(x = m2, y = price, colour = exterior)) +
  geom_point() +
  geom_smooth(method = "lm") +
  ggtitle('Relación precio-superficie, por exterior'),
  
  ggplot(mhp_train, aes(x = rooms, y = price, colour = exterior)) +
  geom_point() +
  geom_smooth(method = "lm") +
  ggtitle('Relación precio-habitaciones, por exterior'),
  
  nrow =1
)
```

```{r}
plot_grid(
  ggplot(mhp_train, aes(x = m2, y = price, colour = elevator)) +
  geom_point() +
  geom_smooth(method = "lm") +
  ggtitle('Relación precio-superficie, por ascensor'),
  
  ggplot(mhp_train, aes(x = rooms, y = price, colour = elevator)) +
  geom_point() +
  geom_smooth(method = "lm") +
  ggtitle('Relación precio-habitaciones, por ascensor'),
  
  nrow =1
)
```

```{r}
plot_grid(
  ggplot(mhp_train, aes(x = m2, y = price, colour = garage)) +
  geom_point() +
  geom_smooth(method = "lm") +
  ggtitle('Relación precio-superficie, por garaje'),
  
  ggplot(mhp_train, aes(x = rooms, y = price, colour = garage)) +
  geom_point() +
  geom_smooth(method = "lm") +
  ggtitle('Relación precio-habitaciones, por garaje'),
  
  nrow =1
)
```

Representando boxplot por distrito se ve claramente que los barrios ricos como Salamanca o Chamberí, a parte de tener precios medios más altos, tienen mayor número de viviendas con precios atípicos (por encima), mientras que en el número de habitaciones no se aprecia una diferencia tan notoria.

```{r}
ggplot(mhp_train, aes(district, price)) +
  geom_boxplot(fill = "#0BB363") +
  labs(y = "Precio", title = "Boxplot de precios por distrito") +
  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 30, hjust = 1))
```

```{r}
ggplot(mhp_train, aes(district, rooms)) +
  geom_boxplot(fill = "#0BB363") +
  labs(y = "Habitaciones", title = "Boxplot de habitaciones por distrito") +
  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 30, hjust = 1))
```

```{r}
ggplot(mhp_train, aes(district, m2)) +
  geom_boxplot(fill = "#0BB363") +
  labs(y = "Metros cuadrados", title = "Boxplot de superficie por distrito") +
  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 30, hjust = 1))
```

En las siguientes figuras se representa el precio medio por distrito y como varía con respecto a otras variables de interés.

```{r}
mhp_train %>%
  group_by(district, m2) %>%
  summarize(avg_price = mean(price)) %>%
  ggplot(aes(x = m2, y = avg_price)) + 
  geom_point(size = 0.5) +
  facet_wrap(~ district)
```

```{r}
mhp_train %>%
  group_by(district, exterior) %>% 
  summarise(avg_price = mean(price)) %>%
  ggplot(aes(x=district, y=avg_price, fill=exterior)) +
  geom_bar(stat = "identity", position = "dodge") + 
  ggtitle("Precio medio por distrito y exterior") +
  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 30, hjust = 1)) + 
  labs(x = "Distrito", y = "Precio medio")
```

```{r}
mhp_train %>%
  group_by(district, elevator) %>% 
  summarise(avg_price = mean(price)) %>%
  ggplot(aes(x=district, y=avg_price, fill=elevator)) +
  geom_bar(stat = "identity", position = "dodge") + 
  ggtitle("Precio medio por distrito y ascensor") +
  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 30, hjust = 1)) + 
  labs(x = "Distrito", y = "Precio medio")
```

```{r}
mhp_train %>%
  group_by(district, garage) %>% 
  summarise(avg_price = mean(price)) %>%
  ggplot(aes(x=district, y=avg_price, fill=garage)) +
  geom_bar(stat = "identity", position = "dodge") + 
  ggtitle("Precio medio por distrito y garaje") +
  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 30, hjust = 1)) + 
  labs(x = "Distrito", y = "Precio medio")
```

# Procesado de variables cualitativas

```{r}
mhp_train %>%
  group_by(house_type) %>%
  summarise(precio_medio = mean(price)) %>%
  arrange(precio_medio)
```

Para el posterior análisis transformamos la columna house_type, agrupando en "piso" (independientemente de la planta en la que esté), "casa" (casa o chalet) y "sotano".

```{r}
mhp_train <- mhp_train %>%
  mutate(tipo_casa = case_when(
    grepl("casa|chalet", house_type, ignore.case = TRUE) ~ "casa",
    grepl("\\bplanta\\s*-?1\\b|semi-?sotano|bajo|sotano", house_type, ignore.case = TRUE) ~ "sotano",
    TRUE ~ "piso"
  ))
mhp_train$tipo_casa <- as.factor(mhp_train$tipo_casa)
```

También se agruparán los distritos en función del precio medio del mismo: caro, medio o barato.

```{r}
mhp_train <- mhp_train %>%
  group_by(district) %>%
  mutate(precio_distrito = mean(price)) %>%
  ungroup()

# Calcular los percentiles
percentiles <- quantile(mhp_train$precio_distrito, probs = c(0, 1/3, 2/3, 1))

# Asignar etiquetas
mhp_train$precio_distrito <- cut(mhp_train$precio_distrito, breaks = percentiles, labels = c("barato", "medio", "caro"), include.lowest = TRUE)
```

Además, de cara a desarrollar algunos modelos, se creará una variable target binaria que dividirá las casas entre "cara" y "barata" (1/0).

```{r}
mhp_train$precio_bin <- ifelse(mhp_train$price > median(mhp_train$price), "cara", "barata")
mhp_train$precio_bin = ifelse(mhp_train$precio_bin == "cara", 1, 0)
mhp_train$precio_bin = factor(mhp_train$precio_bin, levels = c(1,0))
```

```{r}
# Aplicamos todos los cambios también a test.

# Categorizamos house_type
mhp_test <- mhp_test %>%
  mutate(tipo_casa = case_when(
    grepl("casa|chalet", house_type, ignore.case = TRUE) ~ "casa",
    grepl("\\bplanta\\s*-?1\\b|semi-?sotano|bajo|sotano", house_type, ignore.case = TRUE) ~ "sotano",
    TRUE ~ "piso"
  ))
mhp_test$tipo_casa <- as.factor(mhp_test$tipo_casa)

# Categorizamos los distritos
mhp_test <- mhp_test %>%
  group_by(district) %>%
  mutate(precio_distrito = mean(price)) %>%
  ungroup()

percentiles <- quantile(mhp_test$precio_distrito, probs = c(0, 1/3, 2/3, 1))

mhp_test$precio_distrito <- cut(mhp_test$precio_distrito, breaks = percentiles, labels = c("barato", "medio", "caro"), include.lowest = TRUE)

# Creamos variable target
mhp_test$precio_bin <- ifelse(mhp_test$price > median(mhp_test$price), "cara", "barata")
mhp_test$precio_bin = ifelse(mhp_test$precio_bin == "cara", 1, 0)
mhp_test$precio_bin = factor(mhp_test$precio_bin, levels = c(1,0))
```

# Modelo de regresión lineal

Con el dataset ya preparado, se crea un modelo de regresión lineal.

En este caso, tras hacer diversas pruebas se ha optado por introducir sólo 3 variables (tipo_casa, m2 y precio_distrito), alcanzando un R2 de 0.7553.

Esta cifra podía incrementarse algo, sin embargo es a costa de introducir más variables y por tanto más complejidad al modelo, haciéndolo menos explicable.

```{r}
lm_fit <- lm(price ~ m2+tipo_casa+precio_distrito, data=mhp_train)
summary(lm_fit)
coef(lm_fit)
```

```{r}
residuals=lm_fit$residuals
autoplot(lm_fit)
```

Observando los residuos se ve como hay cierta heterocedasticidad y en la gráfica QQ no se ajustan a la normal, por lo que el módelo no es bueno.

```{r}
# Realizar predicciones en la partición test
predictions <- predict(lm_fit, newdata = mhp_test)

# Comparar las predicciones con los valores reales
rmse <- rmse(predictions, mhp_test$price)
mae <- mae(predictions, mhp_test$price)
r2 <- R2(predictions, mhp_test$price)

# Imprimir las métricas de evaluación
cat(paste0("RMSE: ", round(rmse, 2), "\n"))
cat(paste0("MAE: ", round(mae, 2), "\n"))
cat(paste0("R-squared: ", round(r2, 2)))
```

Un R2 de 0.73 (bastante similar al calculado en train) indica que se explica con esa probabilidad la variabilidad de la variable dependiente, por lo tanto podríamos considerarlo razonablemente útil, sin embargo sería preferible mejorar los valores del error de predicción promedio o el cuadrático.

# Conclusiones preliminares

El análisis realizado hasta el momento ha servido para familiarizarse con el mercado inmobiliario de Madrid (o al menos parte de él) y conoce como se comportan algunas de las variables más relevantes en el valor de las viviendas.

Con estos conocimientos se abordarán nuevos modelos para intentar conseguir mejores predicciones y simultaneamente comprender y desarrollar estos mismos modelos.

```{r}
str(mhp_train)
```

# Aprendizaje no supervisado

## K-Means

```{r}
mhp_train_kmeans <- subset(mhp_train, select = c("price", "m2", "rooms", "elevator", "garage", "exterior"))

mhp_train_kmeans$exterior <- as.numeric(mhp_train_kmeans$exterior)
mhp_train_kmeans$elevator <- as.numeric(mhp_train_kmeans$elevator)
mhp_train_kmeans$garage <- as.numeric(mhp_train_kmeans$garage)

# Normalizamos los datos
mhp_train_kmeans <- scale(mhp_train_kmeans)
```

Aplicamos k-means sólo para las variables numéricas. Utilizando la regla del codo vemos que que lo correcto sería coger un k = 3. 

```{r}
fviz_nbclust(mhp_train_kmeans, kmeans, method = "wss")
fviz_nbclust(mhp_train_kmeans, kmeans, method = "silhouette")
```

Aplicamos el algoritmo con k = 3 y vemos el gráfico de clusters que nos crea con k-means.

```{r}
# Definir el número de grupos
k <- 7

# Ejecutar k-means
grupos <- kmeans(mhp_train_kmeans, k)

mhp_train$cluster <- as.factor(grupos$cluster)

# Graficar la relación entre las características y los grupos
ggplot(mhp_train, aes(x=m2, y=price, color=cluster)) + 
  geom_point() +
  ggtitle("Grupos de casas en venta") +
  xlab("Tamaño en m2") +
  ylab("Precio")
```

```{r}
fviz_cluster(grupos, data = mhp_train_kmeans, ellipse.type = "euclid",repel = TRUE,star.plot = TRUE)
fviz_cluster(grupos, data = mhp_train_kmeans, ellipse.type = "norm")
```

# Aprendizaje no supervisado

# Técnicas de reducción de la dimensionalidad

##PCA

Dividimos el dataset quedándonos solo con las columnas numéricas y descartando la columna precio puesto que será de alguna manera nuestra variable dependiente.

```{r}
train_pca <- mhp_train[,c(3:7,10,11,12)]
```

Creamos 3 variables dummy de 3 variables categóricas de si o no.

```{r}
dummy_garaje <- model.matrix(~0 + garage,data = train_pca)
dummy_exterior <- model.matrix(~0 + exterior, data = train_pca)
dummy_ascensor <- model.matrix(~0 + elevator, data = train_pca)
dummy_tipo_casa <- model.matrix(~0 + tipo_casa, data = train_pca)
dummy_distrito <- model.matrix(~0 + precio_distrito, data = train_pca)
```

```{r}
dummy_data <- cbind(train_pca[, c("rooms", "m2")],dummy_exterior,dummy_garaje,dummy_ascensor,dummy_distrito,dummy_tipo_casa)
```

```{r}
prcomp(dummy_data)
```
Podemos observar que en la PC1 lleva un peso casi de 100 la variable m2. En PC2 pasa lo mismo con la variable rooms y en el resto de PC está algo más repartido.

```{r}
summary(prcomp(dummy_data))
```
Al hacer un summary de las variables vemos que la proporción de varianza explicada por la primera componente es de un 99%, es decir, que es la única relevante. Si nos fijamos vemos que la PC1 está explicada casi al 100% por los m2 y si nos fijamos en nuestra tabla vemos que los m2 tienen valores mucho más altos que el resto de variables. Por lo tanto lo que hacemos a continuación es un análisis pero escalando las variables.

```{r}
prcomp(dummy_data, scale = T)
```
En este caso, podemos observar que están mucho más repartidos los pesos en las componentes principales. 


```{r}
pca_result <- prcomp(dummy_data, center = TRUE, scale = TRUE)
summary(pca_result)
```
Observamos que con PC6 ya llegamos al 80% de la proporción de varianza explicada pero vemos algunos saltos interesantes. Para ver cuantas componentes explican el modelo hacemos la regla de codo.

```{r}
plot(pca_result,type = "l",
     main="Variance explained by PCA"
)
```
Al observar el gráfico vemos que la forma del codo sería en la 6,7 aunque no es un gráfico muy claro. 

```{r}
plot(pca_result, main = "Gráfico PCA")
```

# Aprendizaje supervisado

## GLM

```{r}
train_glm <- mhp_train[,c(3:7,10,11,12)]
test_glm <- mhp_test[,c(3:7,10,11,12)]
```

Escalamos las columnas de m2 y rooms.

```{r}
train_glm[,2:3]<- scale(train_glm[,2:3])
test_glm[,2:3]<- scale(test_glm[,2:3])
```


```{r}
glm_mhp = glm(formula = precio_bin ~ exterior + garage + elevator + rooms + precio_distrito + tipo_casa,
                 data = train_glm, 
                 family = binomial)
summary(glm_mhp)
```
En particular, las variables "garage", "elevator", "rooms", "precio_distrito_medio", "precio_distrito_caro" y "plantas bajas" tienen una relación significativa y positiva con la probabilidad de que la vivienda sea "cara", mientras que la variable "rooms" tiene una relación negativa con la probabilidad de que la vivienda sea "cara". Esto no tiene mucho sentido puesto que a más habitaciones más probable que una casa sea cara.
El modelo explica una cantidad significativa de la varianza en la variable respuesta, con un AIC de 4904.4.

```{r}
head(predict(glm_mhp))
```
```{r}
head(fitted(glm_mhp))
```

```{r}
predicciones_glm <- ifelse(test = glm_mhp$fitted.values > 0.5, yes = 1, no = 0)
matriz_confusion_glm <- table(glm_mhp$model$precio_bin, predicciones_glm,
                          dnn = c("observaciones", "predicciones"))
matriz_confusion_glm
```

## KNN

Intentamos ver is hay un número correcto de k-vecinos que podemos usar.

```{r}
library(class)
long = 15
accuracy = rep(0,long)
f1score = rep(0,long)
recall = rep(0,long)
precision = rep(0,long)
for (i in 1:long)
{
  prediccion_knn_cv =knn.cv(mhp_train[,c("exterior","rooms","m2","elevator", "garage")], 
                            k=i, cl=mhp_train$precio_bin)
  accuracy[i] = sum(prediccion_knn_cv == mhp_train$precio_bin) /nrow(mhp_train)
  recall[i] = sum(prediccion_knn_cv == mhp_train$precio_bin & mhp_train$precio_bin == TRUE) / sum(mhp_train$precio_bin == TRUE)
  precision[i] = sum(prediccion_knn_cv == mhp_train$precio_bin & prediccion_knn_cv == TRUE) / sum(prediccion_knn_cv == TRUE)
  f1score[i] = 2*precision[i]*recall[i]/(precision[i]+recall[i])
}
resultados_knn = as.data.frame(cbind(accuracy,f1score,precision,recall))
resultados_knn = resultados_knn %>% mutate(index=as.factor(seq(1:long)))

max(resultados_knn$f1score)
which.max(resultados_knn$f1score)


ggplot(data=resultados_knn,aes(x=index,y=accuracy)) + 
  geom_col(colour="cyan4",fill="cyan3")+
  ggtitle("Accuracy")


ggplot(data=resultados_knn,aes(x=index,y=f1score)) + 
  geom_col(colour="orange4",fill="orange3") +
  ggtitle("F1_score values")

```

Analizando el gráfico no observamos ninguna diferencia, así que cogemos 5 que es el tamaño por defecto que se suele coger.

```{r}
library(distances)
# En train
prediccion_knn5_train =knn.cv(mhp_train[,c("exterior","rooms","m2","elevator", "garage")], 
                              k=5, cl=mhp_train$precio_bin)
confusionMatrix(table(prediccion_knn5_train,mhp_train$precio_bin), positive= "1")

#En test
prediccion_knn5_test=knn(mhp_train[,c("exterior","rooms","m2","elevator", "garage")], mhp_test[,c("exterior","rooms","m2","elevator", "garage")],
                         k=5, cl=mhp_train$precio_bin)
confusionMatrix(table(prediccion_knn5_test,mhp_test$precio_bin), positive= "1")
```

Tras realizar diferentes pruebas quitando variables vemos que si quitamos la variable m2 nos dice que hay muchos empates y no saca nada. Sin embargo, quitando las otras variables varia muy poco el acierto en train y test.
Obteniendo más o menos un 84% de acierto creemos que nos puede servir para clasificar las nuevas casas que entrasen en el dataset, puesto que no hemos sido capaces de mejorar ese %.


## Decision Trees

A continuación hacemos el modelo de arbol de decisión. 

```{r}
library(rpart)
library(rpart.plot)
library(rattle)
arbol <- rpart(precio_bin ~ garage + elevator + rooms + tipo_casa + precio_distrito, data = mhp_train, control = rpart.control(minsplit = 1))
fancyRpartPlot(arbol, sub = "")
```
Calculamos el número de aciertos y nos sale bastante aceptable.

```{r}
tab1 = table(pred = predict(arbol, mhp_test, type = "class"),
obs = mhp_test$precio_bin)
ntest = nrow(mhp_test)
acierto1 = sum(diag(tab1))/ntest
acierto1
```

Para validar el modelo podemos usar las funciones printcp y plotcp. La función printcp nos da el número óptimo de podas basada en el valor cp. La poda se realiza para evitar overfitting sobre los datos. 
El valor de cp ha de ser tal que la tasa de error de validación cruzada sea mínima.

```{r}
printcp(arbol)
```
```{r}
arbol$cptable[which.min(arbol$cptable[, "xerror"]),
"CP"]
```


```{r}
plotcp(arbol)
```
Podamos el árbol como indica la función. 

```{r}
pruneTREE1 = prune(arbol, cp = arbol$cptable[which.min(arbol$cptable[,
"xerror"]), "CP"])
fancyRpartPlot(pruneTREE1, uniform = TRUE, main = "Pruned Classification Tree",
sub = "")
```

```{r}
pruneTREE2 = prune(arbol, cp = arbol$cptable[5, "CP"])
fancyRpartPlot(pruneTREE2, uniform = TRUE, main = "Pruned Classification Tree",
sub = "")
```

```{r}
tab2 = table(pred = predict(pruneTREE2, mhp_test, type = "class"),
obs = mhp_test$precio_bin)
acierto2 = sum(diag(tab2))/ntest
acierto2
```
Nos sale literalmente es mismo resultado.

Creamos la matriz de confusión. 

```{r}
prediccion_1 <- predict(arbol, newdata = mhp_train, type = "class")
```

```{r}
confusionMatrix(prediccion_1, mhp_train[["precio_bin"]])
```


## Random Forest

```{r}
library(randomForest)
# Escalar¡mos la columna 4 en train y test
set.seed(19042023)
mhp_train_scaled <- mhp_train
mhp_train_scaled[, 4] <- scale(mhp_train[, 4])

mhp_test_scaled <- mhp_test
mhp_test_scaled[, 4] <- scale(mhp_test[, 4])

# Nos quedamos con todas las variables menos barrio y distrito porque hay muchas categorias
#Cogemos solo 10 árboles en el parámetro ntree
classifier <- randomForest(x = mhp_train_scaled[, c(3, 4, 5, 6, 7, 10,11)],
                           y = mhp_train_scaled$precio_bin,
                           ntree = 10)
```

```{r}
# Predicción de los resultados con el conjunto de testing
y_pred = predict(classifier, newdata = mhp_test_scaled[,c(3,4,5,6,7,10,11)])
```

```{r}
confusionMatrix(y_pred, mhp_test_scaled[["precio_bin"]])
```
Ahora probamos con 100 árboles aleatorios para ver si cambia mucho el resultado. 

```{r}
set.seed(19042022)
classifier <- randomForest(x = mhp_train_scaled[, c(3, 4, 5, 6, 7, 10,11)],
                           y = mhp_train_scaled$precio_bin,
                           ntree = 100)
```

```{r}
y_pred = predict(classifier, newdata = mhp_test_scaled[,c(3,4,5,6,7,10,11)])
```


```{r}
confusionMatrix(y_pred, mhp_test_scaled[["precio_bin"]])
```
La precisión del modelo es del 0,9007 y el intervalo de confianza del 95% es (0,8908, 0,9099), lo que indica que podemos estar bastante seguros de que la precisión real del modelo está dentro de este rango. El valor de kappa de 0,8013 indica que hay una buena concordancia entre las predicciones del modelo y las observaciones reales.

Además, la sensibilidad del modelo es del 0,8670 y la especificidad del 0,9343. La tasa de detección es del 0,4335 y la prevalencia es del 0,5000. En general, el modelo tiene un desempeño bastante bueno en la clasificación de las viviendas por encima y por debajo del umbral.



## SVM

# Ajuste de hiperparámetros del modelo

# Evaluación y comparación de modelos

# Elección punto de corte

# Redes Bayasianas y/o GAM

```{r}
library(e1071)
```

