---
title: "Madrid House Price"
author: "Sergio Fernández, Miguel Ocón, Enrique Roa"
date: "`r format(Sys.Date(), '%d de %B de %Y')`"
output:
  html_document:
    code_folding: hide
    theme: flatly
    number_sections: yes
    toc: yes
    toc_depth: 2
    toc_float: yes
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	include = TRUE,
	warning = TRUE,
	message = FALSE,
	fig.align = "center",
	out.width = "90%"
)
```

![](Gran_Vía_(Madrid)_1.jpg)

# Introducción y definición de objetivos

El análisis de datos en el mercado inmobiliario es algo muy común y que lleva muchísimos años  desarrollándose. Con el objetivo de predecir que aspectos influyen principalmente en el precio de las casas en Madrid, hemos seleccionado un dataset  ([kaggle - Madrid House Price](https://www.kaggle.com/datasets/kevsde/madrid-house-price)) con viviendas en venta de la capital española.

```{r}
library(readr)
library(dplyr)
library(tidyr)
library(kableExtra)
library(ggplot2)
library(cowplot)
library(ggcorrplot)
library(gmodels)
library(caret)
library(ggfortify)
library(scales)
library(cluster)
library(tidyverse)
library(stringr)
```

```{r}
paste(R.Version()$version.string)
```

```{r}
levels(mhp$house_type)
```


# Análisis exploratorio inicial

## Lectura y preparación de los datos

```{r}
mhp <- read_csv("house_price_madrid_14_08_2022.csv")
```

```{r}
head(mhp, 10) %>%
  kbl() %>%
  kable_material(c("striped", "hover")) %>%
  scroll_box(width = "100%", height = "350px")
```

```{r}
summary(mhp)
```

```{r}
str(mhp) 
```

## Creamos nuestra variable target binaria

```{r}
mhp$cara <- NA
mhp$cara <- ifelse(mhp$price > median(mhp$price), "cara", "barata")

```


El dataset contiene **15.975 observaciones** (correspondientes a una vivienda cada una) y **9 variables** (de las cuales son **6 cualitativas** y **3 cuantitativas**).

A continuación, la descripción de cada una de las variables:

  - **price**: precio
  
  - **house_type**: tipo de vivienda (casa, chalet, piso...)
  
  - **house_type_2**: si es exterior o interior
  
  - **rooms**: número de habitaciones
  
  - **m2**: metros cuadrados
  
  - **elevator**: si tiene ascensor
  
  - **garage**: si incluye garaje
  
  - **neighborhood**: barrio de Madrid
  
  - **district**: distrito de Madrid

## Tratamiento de datos faltantes

Convertimos en NA las siguientes observaciones:

  - La casa de 41 habitaciones (probablemente fueran 4 y está mal imputado)
  
  - Las que tienen menos de 3 m2 (probablemente mal imputados al usar el punto para separar los miles)
  
  - La casa con un precio de 725 (claramente equivocado).

```{r}
mhp$rooms[mhp$rooms > 40] <- NA
mhp$m2[mhp$m2 < 3] <- NA
mhp$price[mhp$price < 1000] <- NA
```

La variable **house_type_2** tiene 469 filas sin datos. Junto a los añadidos anteriormente son el 3.2% del total. Optamos por eliminar estas filas del dataset.

```{r}
sum(is.na(mhp))/nrow(mhp)
mhp <- na.omit(mhp)
```

## Procesado de variables categóricas

```{r}
mhp <- mhp %>% rename(exterior = house_type_2)

mhp$exterior = ifelse(mhp$exterior == "exterior", 1, 0)
mhp$exterior = factor(mhp$exterior, levels = c(1,0))

mhp$elevator = ifelse(mhp$elevator == "TRUE", 1, 0)
mhp$elevator = factor(mhp$elevator, levels = c(1,0))

mhp$garage = ifelse(mhp$garage == "TRUE", 1, 0)
mhp$garage = factor(mhp$garage, levels = c(1,0))

mhp$cara = ifelse(mhp$cara == "cara", 1, 0)
mhp$cara = factor(mhp$cara, levels = c(1,0))
```

Cambiamos el nombre a las planta -1 por sotano puesto que interpretamos que es el mismo tipo de vivienda. 

```{r}
mhp$house_type <- gsub("planta -1", "sotano", mhp$house_type)
  unique(mhp$house_type)
```

```{r}
mhp$house_type <- as.factor(mhp$house_type)
mhp$exterior <- as.factor(mhp$exterior)
mhp$elevator <- as.factor(mhp$elevator)
mhp$garage <- as.factor(mhp$garage)
mhp$neighborhood <- as.factor(mhp$neighborhood)
mhp$district <- as.factor(mhp$district)

mhp$house_type <- factor(mhp$house_type, ordered = TRUE, levels = c("planta -1", "sotano", "semi-sotano", "casa", "chalet", "entreplanta", "bajo", "planta 1", "planta 2", "planta 3", "planta 4", "planta 5", "planta 6", "planta 7", "planta 8", "planta 9", "planta 10", "planta 11", "planta 12", "planta 13", "planta 14", "planta 15", "planta 16", "planta 17", "planta 18", "planta 19", "planta 20"))
```

## División del dataset

Dividimos el dataset en train, test y validation.

```{r}
set.seed(108)
numero_total = nrow(mhp)
# Porcentajes de train, test y validation
w_train = .5
w_test = .25
w_validation = 1 - (w_train + w_test)

# Todos los índices
indices = seq(1:numero_total) 

# Muestreo
indices_train = sample(1:numero_total, numero_total * w_train)
indices_test = sample(indices[-indices_train], numero_total * w_test)
indices_validation = indices[-c(indices_train,indices_test)]

# Agrupamos

mhp_train = mhp[indices_train,]
mhp_test = mhp[indices_test,]
mhp_validation = mhp[indices_validation,]
```

# Análisis univariante

## Análisis de variables cualitativas

**TIPO DE VIVIENDA**

```{r}
merge(setNames(as.data.frame(table(mhp_train$house_type)), c("house_type", "count")),
      setNames(as.data.frame(round(prop.table(table(mhp_train$house_type))*100, 2)), c("house_type", "prop (%)"))
) %>%
  arrange(desc(count)) %>%
  kbl() %>%
  kable_material(c("striped", "hover")) %>%
  scroll_box(width = "100%", height = "350px")
```

```{r}
ggplot(mhp_train, aes(house_type)) +
  geom_bar(fill = "#0BB363") +
  coord_flip() +
  labs(x = "Tipo de vivienda", y = "Número de viviendas", title = "Viviendas por tipo") +
  theme(plot.title = element_text(hjust = 0.5))
```

**EXTERIOR**

```{r}
merge(setNames(as.data.frame(table(mhp_train$exterior)), c("exterior", "count")),
      setNames(as.data.frame(round(prop.table(table(mhp_train$exterior))*100, 2)), c("exterior", "prop (%)"))
) %>%
  kbl() %>%
  kable_material(c("striped", "hover"))
```

```{r}
ggplot(mhp_train, aes(exterior)) +
  geom_bar(fill = "#0BB363") +
  labs(x = "Exterior", y = "Número de vivienda de viviendas", title = "Viviendas exteriores") +
  theme(plot.title = element_text(hjust = 0.5))
```
**ASCENSOR**

```{r}
merge(setNames(as.data.frame(table(mhp_train$elevator)), c("elevator", "count")),
      setNames(as.data.frame(round(prop.table(table(mhp_train$elevator))*100, 2)), c("elevator", "prop (%)"))
) %>%
  kbl() %>%
  kable_material(c("striped", "hover"))
```

```{r}
ggplot(mhp_train, aes(elevator)) +
  geom_bar(fill = "#0BB363") +
  labs(x = "Ascensor", y = "Número de viviendas", title = "Viviendas con ascensor") +
  theme(plot.title = element_text(hjust = 0.5))
```

**GARAJE**

```{r}
merge(setNames(as.data.frame(table(mhp_train$garage)), c("garage", "count")),
      setNames(as.data.frame(round(prop.table(table(mhp_train$garage))*100, 2)), c("garage", "prop (%)"))
) %>%
  kbl() %>%
  kable_material(c("striped", "hover"))
```

```{r}
ggplot(mhp_train, aes(garage)) +
  geom_bar(fill = "#0BB363") +
  labs(x = "Garaje", y = "Número de viviendas", title = "Viviendas con garaje") +
  theme(plot.title = element_text(hjust = 0.5))
```

**BARRIO**

```{r}
merge(setNames(as.data.frame(table(mhp_train$neighborhood)), c("neighborhood", "count")),
      setNames(as.data.frame(round(prop.table(table(mhp_train$neighborhood))*100, 2)), c("neighborhood", "prop (%)"))
) %>%
  kbl() %>%
  kable_material(c("striped", "hover")) %>%
  scroll_box(width = "100%", height = "350px")
```

**DISTRITO**

```{r}
merge(setNames(as.data.frame(table(mhp_train$district)), c("district", "count")),
      setNames(as.data.frame(round(prop.table(table(mhp_train$district))*100, 2)), c("district", "prop (%)"))
) %>%
  arrange(desc(count)) %>%
  kbl() %>%
  kable_material(c("striped", "hover")) %>%
  scroll_box(width = "100%", height = "350px")
```

```{r}
ggplot(mhp_train, aes(district)) +
  geom_bar(fill = "#0BB363") +
  labs(x = "Distrito", y = "Número de viviendas", title = "Viviendas por distrito") +
  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 30, hjust = 1))
```

## Análisis de variables cuantitativas

**PRECIO**

```{r}
data.frame(summarise(mhp_train,
                     min = min(price),
                     max = max(price),
                     median = median(price),
                     mean = mean(price),
                     sd = sd(price))) %>%
  kbl() %>%
  kable_material(c("striped", "hover"))
```

```{r}
ggplot(mhp_train, aes(y = price)) +
  geom_boxplot(fill = "#0BB363") +
  labs(y = "Precio", title = "Boxplot de precios") +
  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 30, hjust = 1))
```

```{r}
ggplot(mhp_train, aes(price)) +
  geom_histogram(aes(y=..density..), bins = 50, position = "dodge", fill = "#0BB363") +
  geom_density(alpha=.2, fill = "red") +
  labs(x = "Precio", y = "Número de viviendas", title = "Viviendas por Precio") +
  theme(plot.title = element_text(hjust = 0.5))
```

**HABITACIONES**

```{r}
data.frame(summarise(mhp_train,
                     min = min(rooms),
                     max = max(rooms),
                     median = median(rooms),
                     mean = mean(rooms),
                     sd = sd(rooms))) %>%
  kbl() %>%
  kable_material(c("striped", "hover"))
```

```{r}
ggplot(mhp_train, aes(y = rooms)) +
  geom_boxplot(fill = "#0BB363") +
  labs(y = "Habitaciones", title = "Boxplot de habitaciones") +
  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 30, hjust = 1))
```

```{r}
ggplot(mhp_train, aes(rooms)) +
  geom_histogram(aes(), bins = 16, position = "dodge", fill = "#0BB363") +
  geom_density(alpha=.2, fill = "red") +
  labs(x = "Habitaciones", y = "Número de viviendas", title = "Viviendas por número de habitaciones") +
  theme(plot.title = element_text(hjust = 0.5))
```

**M²**

```{r}
data.frame(summarise(mhp_train,
                     min = min(m2),
                     max = max(m2),
                     median = median(m2),
                     mean = mean(m2),
                     sd = sd(m2))) %>%
  kbl() %>%
  kable_material(c("striped", "hover"))
```

```{r}
ggplot(mhp_train, aes(y = m2)) +
  geom_boxplot(fill = "#0BB363") +
  labs(y = "Metros cuadrados", title = "Boxplot de superficies") +
  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 30, hjust = 1))
```

```{r}
ggplot(mhp_train, aes(m2)) +
  geom_histogram(aes(y=..density..), bins = 50, position = "dodge", fill = "#0BB363") +
  geom_density(alpha=.5, fill = "red") +
  labs(x = "Metros cuadrados", y = "Número de viviendas", title = "Viviendas por metros cuadrados") +
  theme(plot.title = element_text(hjust = 0.5))
```
# Función de densidad del precio de las viviendas
```{r}
ggplot(data = mhp_train, aes(price))+
  geom_density(alpha=1, fill = "red")+
theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 30))+
  labs(x = "Precio", y = "Número viviendas", title = "Función densidad precio viviendas")+
scale_x_continuous(breaks = pretty(mhp_train$price, n = 10),labels = comma_format()) +
  scale_y_continuous(labels = comma_format())
```


# Análisis multivariante

```{r}
plot_grid(
  ggcorrplot(cor(mhp_train %>% select_if(is.numeric)),type = "lower", lab=TRUE),
  
  ggplot(mhp_train, aes(x = m2, y = price)) +
  geom_point() +
  geom_smooth() +
  ggtitle('Relación entre el precio y los metros cuadrados'),
  
  ggplot(mhp_train, aes(x = rooms, y = price)) +
  geom_point() +
  geom_smooth() +
  ggtitle('Relación entre el precio y el número de habitaciones'),
  
  ggplot(mhp_train, aes(x = rooms, y = m2)) +
  geom_point() +
  geom_smooth() +
  ggtitle('Relación entre los metros cuadrados y el número de habitaciones'),
  
  nrow = 2
)
```

```{r}
plot_grid(
  ggplot(mhp_train, aes(x = m2, y = price, colour = exterior)) +
  geom_point() +
  geom_smooth(method = "lm") +
  ggtitle('Relación precio-superficie, por exterior'),
  
  ggplot(mhp_train, aes(x = rooms, y = price, colour = exterior)) +
  geom_point() +
  geom_smooth(method = "lm") +
  ggtitle('Relación precio-habitaciones, por exterior'),
  
  nrow =1
)
```

```{r}
plot_grid(
  ggplot(mhp_train, aes(x = m2, y = price, colour = elevator)) +
  geom_point() +
  geom_smooth(method = "lm") +
  ggtitle('Relación precio-superficie, por ascensor'),
  
  ggplot(mhp_train, aes(x = rooms, y = price, colour = elevator)) +
  geom_point() +
  geom_smooth(method = "lm") +
  ggtitle('Relación precio-habitaciones, por ascensor'),
  
  nrow =1
)
```

```{r}
plot_grid(
  ggplot(mhp_train, aes(x = m2, y = price, colour = garage)) +
  geom_point() +
  geom_smooth(method = "lm") +
  ggtitle('Relación precio-superficie, por garaje'),
  
  ggplot(mhp_train, aes(x = rooms, y = price, colour = garage)) +
  geom_point() +
  geom_smooth(method = "lm") +
  ggtitle('Relación precio-habitaciones, por garaje'),
  
  nrow =1
)
```

```{r}
ggplot(mhp_train, aes(district, price)) +
  geom_boxplot(fill = "#0BB363") +
  labs(y = "Precio", title = "Boxplot de precios por distrito") +
  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 30, hjust = 1))
```

```{r}
ggplot(mhp_train, aes(district, rooms)) +
  geom_boxplot(fill = "#0BB363") +
  labs(y = "Habitaciones", title = "Boxplot de habitaciones por distrito") +
  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 30, hjust = 1))
```

```{r}
ggplot(mhp_train, aes(district, m2)) +
  geom_boxplot(fill = "#0BB363") +
  labs(y = "Metros cuadrados", title = "Boxplot de superficie por distrito") +
  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 30, hjust = 1))
```

```{r}
plot_grid(
  ggplot(mhp_train, aes(x = m2, y = price, colour = district)) +
  geom_point() +
  geom_smooth(method = "lm") +
  ggtitle('Relación entre el precio y la superficie, por distrito'),
  
  ggplot(mhp_train, aes(x = rooms, y = price, colour = district)) +
  geom_point() +
  geom_smooth(method = "lm") +
  ggtitle('Relación entre el precio y las habitaciones, por distrito'),
  
  nrow =1
)
```

```{r}
mhp_train %>%
  group_by(district, m2) %>%
  summarize(avg_price = mean(price)) %>%
  ggplot(aes(x = m2, y = avg_price)) + 
  geom_point(size = 0.5) +
  facet_wrap(~ district)
```

```{r}
mhp_train %>%
  group_by(district, exterior) %>% 
  summarise(avg_price = mean(price)) %>%
  ggplot(aes(x=district, y=avg_price, fill=exterior)) +
  geom_bar(stat = "identity", position = "dodge") + 
  ggtitle("Precio medio por distrito y exterior") +
  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 30, hjust = 1)) + 
  labs(x = "Distrito", y = "Precio medio")
```

```{r}
mhp_train %>%
  group_by(district, elevator) %>% 
  summarise(avg_price = mean(price)) %>%
  ggplot(aes(x=district, y=avg_price, fill=elevator)) +
  geom_bar(stat = "identity", position = "dodge") + 
  ggtitle("Precio medio por distrito y ascensor") +
  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 30, hjust = 1)) + 
  labs(x = "Distrito", y = "Precio medio")
```

```{r}
mhp_train %>%
  group_by(district, garage) %>% 
  summarise(avg_price = mean(price)) %>%
  ggplot(aes(x=district, y=avg_price, fill=garage)) +
  geom_bar(stat = "identity", position = "dodge") + 
  ggtitle("Precio medio por distrito y garaje") +
  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 30, hjust = 1)) + 
  labs(x = "Distrito", y = "Precio medio")
```

# Transformación de variables

## Transformación de variables cuantitativas

```{r}
plot_grid(
  
  ggplot(mhp_train, aes(x = m2, y = price)) +
  geom_point() +
  geom_smooth() +
  ggtitle('Relación entre el precio y los metros cuadrados'),
  
  ggplot(mhp_train, aes(x = rooms, y = price)) +
  geom_point() +
  geom_smooth() +
  ggtitle('Relación entre el precio y el múmero de habitaciones'),
  
  ggplot(mhp_train, aes(x = rooms, y = m2)) +
  geom_point() +
  geom_smooth() +
  ggtitle('Relación entre los metros cuadrados y el número de habitaciones'),
  
  nrow = 2
)
```

# Modelo de regresión lineal

```{r}
lm_fit <- lm(price ~ m2+rooms+exterior+elevator+garage, data=mhp_train)
summary(lm_fit)
coef(lm_fit)
```

```{r}
library(ggfortify)
residuals=lm_fit$residuals
autoplot(lm_fit)
```

# Conclusiones preliminares

\#.
Para el posterior análisis cambiamos algunas variables para agruparlas y hacer el análisis lo más eficiente posible.

```{r}
mhp <- mhp %>%
  mutate(house_type = ifelse(!is.na(as.numeric(str_extract(house_type, "\\d+"))) & as.numeric(str_extract(house_type, "\\d+")) > 1, "plantas altas", house_type))
unique(mhp$house_type)
```

Volvemos a dividir el dataset original con las variables ya cambiadas.

```{r}
set.seed(108)
numero_total = nrow(mhp)
# Porcentajes de train, test y validation
w_train = .5
w_test = .25
w_validation = 1 - (w_train + w_test)

# Todos los índices
indices = seq(1:numero_total) 

# Muestreo
indices_train = sample(1:numero_total, numero_total * w_train)
indices_test = sample(indices[-indices_train], numero_total * w_test)
indices_validation = indices[-c(indices_train,indices_test)]

# Agrupamos

mhp_train = mhp[indices_train,]
mhp_test = mhp[indices_test,]
mhp_validation = mhp[indices_validation,]
```



# Aprendizaje no supervisado

# Técnicas de reducción de la dimensionalidad

##PCA

Dividimos el dataset quedándonos solo con las columnas numéricas y descartando la columna precio puesto que será de alguna manera nuestra variable dependiente.

```{r}
train <- mhp_train[,c(3:7)]
```

Creamos 3 variables dummy de 3 variables categóricas de si o no.

```{r}
dummy_garaje <- model.matrix(~0 + garage,data = train)
dummy_exterior <- model.matrix(~0 + exterior, data = train)
dummy_ascensor <- model.matrix(~0 + elevator, data = train)

```



```{r}
dummy_data <- cbind(train[, c("rooms", "m2")],dummy_exterior,dummy_garaje,dummy_ascensor)
```


```{r}
pca_result <- prcomp(dummy_data, center = TRUE, scale = TRUE)
summary(pca_result)
```

```{r}
plot(pca_result,type = "l",
     main="Variance explained by PCA"
)
```

```{r}
plot(pca_result, main = "Gráfico PCA")
```

# Aprendizaje supervisado

## GLM

```{r}
train_glm <- mhp_train[,c(3:7,10)]
test_glm <- mhp_test[,c(3:7,10)]
```

```{r}
glm_mhp = glm(formula = cara ~ exterior + garage + elevator + rooms,
                 data = train_glm, 
                 family = binomial)
```

```{r}
# Predicción de los resultados con el conjunto de testing
prob_pred = predict(glm_mhp, type = "response",
                    newdata = test_glm[,-6])
y_pred = ifelse(prob_pred> 0.5, 1, 0)

# Crear la matriz de confusión
cm = table(test_glm[, 6], y_pred)
```


```{r}
library(effects)
efectos <- allEffects(glm_mhp)
plot(efectos)
```


## KNN

Aplicamos k-means sólo para las variables numéricas. Utilizando la regla del codo vemos que que lo correcto sería coger un k = 4. 

```{r}
X = mhp_train[,c(4,5)]
set.seed(6)
wcss = vector()
for (i in 1:10){
  wcss[i] <- sum(kmeans(X, i)$withinss)
}
plot(1:10, wcss, type = 'b', main = "Método del codo",
     xlab = "Número de clusters (k)", ylab = "WCSS(k)")
```

Aplicamos el algoritmo con k = 3 y vemos el gráfico de clusters que nos crea con k-means.
```{r}
# Aplicar el algoritmo de k-means con k óptimo
library(cluster)
kmeans <- kmeans(X, 3, iter.max = 300, nstart = 10)
clusplot(X, 
         kmeans$cluster,
         lines = 0,
         shade = TRUE,
         color = TRUE,
         labels = 1,
         plotchar = FALSE,
         span = TRUE,
         main = "Clustering de casas",
         xlab = "habitaciones",
         ylab = "m2"
         )
```

## KNN

Intentamos ver is hay un número correcto de k-vecinos que podemos usar.

```{r}
library(tidyverse)
library(class)
long = 15
accuracy = rep(0,long)
f1score = rep(0,long)
recall = rep(0,long)
precision = rep(0,long)
for (i in 1:long)
{
  prediccion_knn_cv =knn.cv(mhp_train[,c("exterior","rooms","m2","elevator", "garage")], 
                            k=i, cl=mhp_train$cara)
  accuracy[i] = sum(prediccion_knn_cv == mhp_train$cara) /nrow(mhp_train)
  recall[i] = sum(prediccion_knn_cv == mhp_train$cara & mhp_train$cara == TRUE) / sum(mhp_train$cara == TRUE)
  precision[i] = sum(prediccion_knn_cv == mhp_train$cara & prediccion_knn_cv == TRUE) / sum(prediccion_knn_cv == TRUE)
  f1score[i] = 2*precision[i]*recall[i]/(precision[i]+recall[i])
}
resultados_knn = as.data.frame(cbind(accuracy,f1score,precision,recall))
resultados_knn = resultados_knn %>% mutate(index=as.factor(seq(1:long)))

max(resultados_knn$f1score)
which.max(resultados_knn$f1score)


ggplot(data=resultados_knn,aes(x=index,y=accuracy)) + 
  geom_col(colour="cyan4",fill="cyan3")+
  ggtitle("Accuracy")


ggplot(data=resultados_knn,aes(x=index,y=f1score)) + 
  geom_col(colour="orange4",fill="orange3") +
  ggtitle("F1_score values")

```

Analizando el gráfico no observamos ninguna diferencia, así que cogemos 5 que es el tamaño por defecto que se suele coger.

```{r}
library(distances)
# En train
prediccion_knn5_train =knn.cv(mhp_train[,c("exterior","rooms","m2","elevator", "garage")], 
                              k=5, cl=mhp_train$cara)
confusionMatrix(table(prediccion_knn5_train,mhp_train$cara), positive= "1")

#En test
prediccion_knn5_test=knn(mhp_train[,c("exterior","rooms","m2","elevator", "garage")], mhp_test[,c("exterior","rooms","m2","elevator", "garage")],
                         k=5, cl=mhp_train$cara)
confusionMatrix(table(prediccion_knn5_test,mhp_test$cara), positive= "1")
```

Tras realizar diferentes pruebas quitando variables vemos que si quitamos la variable m2 nos dice que hay muchos empates y no saca nada. Sin embargo, quitando las otras variables varia muy poco el acierto en train y test.
Obteniendo más o menos un 84% de acierto creemos que nos puede servir para clasificar las nuevas casas que entrasen en el dataset, puesto que no hemos sido capaces de mejorar ese %.

```{r}
# Crear la matriz de confusión
cm = table(mhp_test[, 10], y_pred)
```

## Decision Trees
```{r}
library(rpart)
library(rpart.plot)
arbol <- rpart(cara ~ garage + elevator + rooms, data = mhp_train)
rpart.plot(arbol)
text(arbol)
```

```{r}
prediccion_1 <- predict(arbol, newdata = mhp_train, type = "class")
```

```{r}
confusionMatrix(prediccion_1, mhp_train[["cara"]])
```


## Random Forest

```{r}
library(randomForest)
# Nos quedamos con todas las variables menos barrio porque hay muchas categorias
classifier = randomForest(x = mhp_train[,c(2,3,4,5,6,7,9)],
                          y = mhp_train$cara,
                          ntree = 10)
```

```{r}
# Predicción de los resultados con el conjunto de testing
y_pred = predict(classifier, newdata = mhp_test[,c(2,3,4,5,6,7,9)])
```


```{r}
# Crear la matriz de confusión
cm = table(mhp_test[,10], y_pred)
```


## SVM

# Ajuste de hiperparámetros del modelo

# Evaluación y comparación de modelos

# Elección punto de corte

# Redes Bayasianas y/o GAM