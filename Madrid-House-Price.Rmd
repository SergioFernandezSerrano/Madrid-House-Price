---
title: "Madrid House Price"
author: "Sergio Fernández, Miguel Ocón, Enrique Roa"
date: "`r format(Sys.Date(), '%d de %B de %Y')`"
output:
  html_document:
    code_folding: hide
    theme: flatly
    number_sections: yes
    toc: yes
    toc_depth: 2
    toc_float: yes
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	include = TRUE,
	warning = TRUE,
	message = FALSE,
	fig.align = "center",
	out.width = "90%"
)
```

![](Gran_Vía_(Madrid)_1.jpg)

# Introducción y definición de objetivos

El análisis de datos en el mercado inmobiliario es algo muy común y que lleva muchísimos años  desarrollándose. Con el objetivo de predecir que aspectos influyen principalmente en el precio de las casas en Madrid, hemos seleccionado un dataset  ([kaggle - Madrid House Price](https://www.kaggle.com/datasets/kevsde/madrid-house-price)) con viviendas en venta de la capital española.

```{r}
library(readr)
library(dplyr)
library(tidyr)
library(kableExtra)
library(ggplot2)
library(cowplot)
library(ggcorrplot)
library(gmodels)
library(caret)
library(ggfortify)
library(scales)
library(cluster)
library(tidyverse)
library(stringr)
library(ggfortify)
```

```{r}
paste(R.Version()$version.string)
```
# Análisis exploratorio inicial

## Lectura y preparación de los datos

```{r}
mhp <- read_csv("house_price_madrid_14_08_2022.csv")
```

```{r}
head(mhp, 10) %>%
  kbl() %>%
  kable_material(c("striped", "hover")) %>%
  scroll_box(width = "100%", height = "350px")
```

```{r}
summary(mhp)
```

```{r}
str(mhp) 
```

El dataset contiene **15.975 observaciones** (correspondientes a una vivienda cada una) y **9 variables** (de las cuales son **6 cualitativas** y **3 cuantitativas**).

A continuación, la descripción de cada una de las variables:

  - **price**: precio
  
  - **house_type**: tipo de vivienda (casa, chalet, piso...)
  
  - **house_type_2**: si es exterior o interior
  
  - **rooms**: número de habitaciones
  
  - **m2**: metros cuadrados
  
  - **elevator**: si tiene ascensor
  
  - **garage**: si incluye garaje
  
  - **neighborhood**: barrio de Madrid
  
  - **district**: distrito de Madrid

## Tratamiento de datos faltantes

Convertimos en NA las siguientes observaciones:

  - La casa de 41 habitaciones (probablemente fueran 4 y está mal imputado)
  
  - Las que tienen menos de 3 m2 (probablemente mal imputados al usar el punto para separar los miles)
  
  - La casa con un precio de 725 (claramente equivocado).

```{r}
mhp$rooms[mhp$rooms > 40] <- NA
mhp$m2[mhp$m2 < 3] <- NA
mhp$price[mhp$price < 1000] <- NA
```

La variable **house_type_2** tiene 469 filas sin datos. Junto a los añadidos anteriormente son el 3.2% del total. Optamos por eliminar estas filas del dataset.

```{r}
sum(is.na(mhp))/nrow(mhp)
mhp <- na.omit(mhp)
```

```{r}
# Preparación de los datos. Convertimos a factores las variables que son categóricas y a 1-0 las binarias.

mhp <- mhp %>% rename(exterior = house_type_2)
mhp$exterior = ifelse(mhp$exterior == "exterior", 1, 0)
mhp$exterior = factor(mhp$exterior, levels = c(1,0))

mhp$elevator = ifelse(mhp$elevator == "TRUE", 1, 0)
mhp$elevator = factor(mhp$elevator, levels = c(1,0))

mhp$garage = ifelse(mhp$garage == "TRUE", 1, 0)
mhp$garage = factor(mhp$garage, levels = c(1,0))

mhp$house_type <- as.factor(mhp$house_type)
mhp$exterior <- as.factor(mhp$exterior)
mhp$elevator <- as.factor(mhp$elevator)
mhp$garage <- as.factor(mhp$garage)
mhp$neighborhood <- as.factor(mhp$neighborhood)
mhp$district <- as.factor(mhp$district)
```

## División del dataset

Dividimos el dataset en train, test y validation.

```{r}
set.seed(108)
numero_total = nrow(mhp)
# Porcentajes de train, test y validation
w_train = .5
w_test = .25
w_validation = 1 - (w_train + w_test)

# Todos los índices
indices = seq(1:numero_total) 

# Muestreo
indices_train = sample(1:numero_total, numero_total * w_train)
indices_test = sample(indices[-indices_train], numero_total * w_test)
indices_validation = indices[-c(indices_train,indices_test)]

# Agrupamos

mhp_train = mhp[indices_train,]
mhp_test = mhp[indices_test,]
mhp_validation = mhp[indices_validation,]
```

# Análisis univariante

## Análisis de variables cualitativas

**TIPO DE VIVIENDA**

```{r}
merge(setNames(as.data.frame(table(mhp_train$house_type)), c("house_type", "count")),
      setNames(as.data.frame(round(prop.table(table(mhp_train$house_type))*100, 2)), c("house_type", "prop (%)"))
) %>%
  arrange(desc(count)) %>%
  kbl() %>%
  kable_material(c("striped", "hover")) %>%
  scroll_box(width = "100%", height = "350px")
```

```{r}
ggplot(mhp_train, aes(house_type)) +
  geom_bar(fill = "#0BB363") +
  coord_flip() +
  labs(x = "Tipo de vivienda", y = "Número de viviendas", title = "Viviendas por tipo") +
  theme(plot.title = element_text(hjust = 0.5))
```

**EXTERIOR**

```{r}
merge(setNames(as.data.frame(table(mhp_train$exterior)), c("exterior", "count")),
      setNames(as.data.frame(round(prop.table(table(mhp_train$exterior))*100, 2)), c("exterior", "prop (%)"))
) %>%
  kbl() %>%
  kable_material(c("striped", "hover"))
```

```{r}
ggplot(mhp_train, aes(exterior)) +
  geom_bar(fill = "#0BB363") +
  labs(x = "Exterior", y = "Número de vivienda de viviendas", title = "Viviendas exteriores") +
  theme(plot.title = element_text(hjust = 0.5))
```
**ASCENSOR**

```{r}
merge(setNames(as.data.frame(table(mhp_train$elevator)), c("elevator", "count")),
      setNames(as.data.frame(round(prop.table(table(mhp_train$elevator))*100, 2)), c("elevator", "prop (%)"))
) %>%
  kbl() %>%
  kable_material(c("striped", "hover"))
```

```{r}
ggplot(mhp_train, aes(elevator)) +
  geom_bar(fill = "#0BB363") +
  labs(x = "Ascensor", y = "Número de viviendas", title = "Viviendas con ascensor") +
  theme(plot.title = element_text(hjust = 0.5))
```

**GARAJE**

```{r}
merge(setNames(as.data.frame(table(mhp_train$garage)), c("garage", "count")),
      setNames(as.data.frame(round(prop.table(table(mhp_train$garage))*100, 2)), c("garage", "prop (%)"))
) %>%
  kbl() %>%
  kable_material(c("striped", "hover"))
```

```{r}
ggplot(mhp_train, aes(garage)) +
  geom_bar(fill = "#0BB363") +
  labs(x = "Garaje", y = "Número de viviendas", title = "Viviendas con garaje") +
  theme(plot.title = element_text(hjust = 0.5))
```

**BARRIO**

```{r}
merge(setNames(as.data.frame(table(mhp_train$neighborhood)), c("neighborhood", "count")),
      setNames(as.data.frame(round(prop.table(table(mhp_train$neighborhood))*100, 2)), c("neighborhood", "prop (%)"))
) %>%
  kbl() %>%
  kable_material(c("striped", "hover")) %>%
  scroll_box(width = "100%", height = "350px")
```

**DISTRITO**

```{r}
merge(setNames(as.data.frame(table(mhp_train$district)), c("district", "count")),
      setNames(as.data.frame(round(prop.table(table(mhp_train$district))*100, 2)), c("district", "prop (%)"))
) %>%
  arrange(desc(count)) %>%
  kbl() %>%
  kable_material(c("striped", "hover")) %>%
  scroll_box(width = "100%", height = "350px")
```

```{r}
ggplot(mhp_train, aes(district)) +
  geom_bar(fill = "#0BB363") +
  labs(x = "Distrito", y = "Número de viviendas", title = "Viviendas por distrito") +
  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 30, hjust = 1))
```

## Análisis de variables cuantitativas

**PRECIO**

```{r}
data.frame(summarise(mhp_train,
                     min = min(price),
                     max = max(price),
                     median = median(price),
                     mean = mean(price),
                     sd = sd(price))) %>%
  kbl() %>%
  kable_material(c("striped", "hover"))
```

```{r}
ggplot(mhp_train, aes(y = price)) +
  geom_boxplot(fill = "#0BB363") +
  labs(y = "Precio", title = "Boxplot de precios") +
  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 30, hjust = 1))
```

```{r}
ggplot(mhp_train, aes(price)) +
  geom_histogram(aes(y=..density..), bins = 50, position = "dodge", fill = "#0BB363") +
  geom_density(alpha=.2, fill = "red") +
  labs(x = "Precio", y = "Número de viviendas", title = "Viviendas por Precio") +
  scale_x_continuous(breaks = pretty(mhp_train$price, n = 10),labels = comma_format()) +
  scale_y_continuous(labels = comma_format()) +
  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 30))
```

**HABITACIONES**

```{r}
data.frame(summarise(mhp_train,
                     min = min(rooms),
                     max = max(rooms),
                     median = median(rooms),
                     mean = mean(rooms),
                     sd = sd(rooms))) %>%
  kbl() %>%
  kable_material(c("striped", "hover"))
```

```{r}
ggplot(mhp_train, aes(y = rooms)) +
  geom_boxplot(fill = "#0BB363") +
  labs(y = "Habitaciones", title = "Boxplot de habitaciones") +
  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 30, hjust = 1))
```

```{r}
ggplot(mhp_train, aes(rooms)) +
  geom_histogram(aes(), bins = 16, position = "dodge", fill = "#0BB363") +
  geom_density(alpha=.2, fill = "red") +
  labs(x = "Habitaciones", y = "Número de viviendas", title = "Viviendas por número de habitaciones") +
  theme(plot.title = element_text(hjust = 0.5))
```

**M²**

```{r}
data.frame(summarise(mhp_train,
                     min = min(m2),
                     max = max(m2),
                     median = median(m2),
                     mean = mean(m2),
                     sd = sd(m2))) %>%
  kbl() %>%
  kable_material(c("striped", "hover"))
```

```{r}
ggplot(mhp_train, aes(y = m2)) +
  geom_boxplot(fill = "#0BB363") +
  labs(y = "Metros cuadrados", title = "Boxplot de superficies") +
  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 30, hjust = 1))
```

```{r}
ggplot(mhp_train, aes(m2)) +
  geom_histogram(aes(y=..density..), bins = 50, position = "dodge", fill = "#0BB363") +
  geom_density(alpha=.5, fill = "red") +
  labs(x = "Metros cuadrados", y = "Número de viviendas", title = "Viviendas por metros cuadrados") +
  theme(plot.title = element_text(hjust = 0.5))
```

# Análisis multivariante

```{r}
plot_grid(
  ggcorrplot(cor(mhp_train %>% select_if(is.numeric)),type = "lower", lab=TRUE),
  
  ggplot(mhp_train, aes(x = m2, y = price)) +
  geom_point() +
  geom_smooth() +
  ggtitle('Relación entre el precio y los metros cuadrados'),
  
  ggplot(mhp_train, aes(x = rooms, y = price)) +
  geom_point() +
  geom_smooth() +
  ggtitle('Relación entre el precio y el número de habitaciones'),
  
  ggplot(mhp_train, aes(x = rooms, y = m2)) +
  geom_point() +
  geom_smooth() +
  ggtitle('Relación entre los metros cuadrados y el número de habitaciones'),
  
  nrow = 2
)
```

```{r}
plot_grid(
  ggplot(mhp_train, aes(x = m2, y = price, colour = exterior)) +
  geom_point() +
  geom_smooth(method = "lm") +
  ggtitle('Relación precio-superficie, por exterior'),
  
  ggplot(mhp_train, aes(x = rooms, y = price, colour = exterior)) +
  geom_point() +
  geom_smooth(method = "lm") +
  ggtitle('Relación precio-habitaciones, por exterior'),
  
  nrow =1
)
```

```{r}
plot_grid(
  ggplot(mhp_train, aes(x = m2, y = price, colour = elevator)) +
  geom_point() +
  geom_smooth(method = "lm") +
  ggtitle('Relación precio-superficie, por ascensor'),
  
  ggplot(mhp_train, aes(x = rooms, y = price, colour = elevator)) +
  geom_point() +
  geom_smooth(method = "lm") +
  ggtitle('Relación precio-habitaciones, por ascensor'),
  
  nrow =1
)
```

```{r}
plot_grid(
  ggplot(mhp_train, aes(x = m2, y = price, colour = garage)) +
  geom_point() +
  geom_smooth(method = "lm") +
  ggtitle('Relación precio-superficie, por garaje'),
  
  ggplot(mhp_train, aes(x = rooms, y = price, colour = garage)) +
  geom_point() +
  geom_smooth(method = "lm") +
  ggtitle('Relación precio-habitaciones, por garaje'),
  
  nrow =1
)
```

```{r}
ggplot(mhp_train, aes(district, price)) +
  geom_boxplot(fill = "#0BB363") +
  labs(y = "Precio", title = "Boxplot de precios por distrito") +
  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 30, hjust = 1))
```

```{r}
ggplot(mhp_train, aes(district, rooms)) +
  geom_boxplot(fill = "#0BB363") +
  labs(y = "Habitaciones", title = "Boxplot de habitaciones por distrito") +
  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 30, hjust = 1))
```

```{r}
ggplot(mhp_train, aes(district, m2)) +
  geom_boxplot(fill = "#0BB363") +
  labs(y = "Metros cuadrados", title = "Boxplot de superficie por distrito") +
  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 30, hjust = 1))
```

```{r}
plot_grid(
  ggplot(mhp_train, aes(x = m2, y = price, colour = district)) +
  geom_point() +
  geom_smooth(method = "lm") +
  ggtitle('Relación entre el precio y la superficie, por distrito'),
  
  ggplot(mhp_train, aes(x = rooms, y = price, colour = district)) +
  geom_point() +
  geom_smooth(method = "lm") +
  ggtitle('Relación entre el precio y las habitaciones, por distrito'),
  
  nrow =1
)
```

```{r}
mhp_train %>%
  group_by(district, m2) %>%
  summarize(avg_price = mean(price)) %>%
  ggplot(aes(x = m2, y = avg_price)) + 
  geom_point(size = 0.5) +
  facet_wrap(~ district)
```

```{r}
mhp_train %>%
  group_by(district, exterior) %>% 
  summarise(avg_price = mean(price)) %>%
  ggplot(aes(x=district, y=avg_price, fill=exterior)) +
  geom_bar(stat = "identity", position = "dodge") + 
  ggtitle("Precio medio por distrito y exterior") +
  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 30, hjust = 1)) + 
  labs(x = "Distrito", y = "Precio medio")
```

```{r}
mhp_train %>%
  group_by(district, elevator) %>% 
  summarise(avg_price = mean(price)) %>%
  ggplot(aes(x=district, y=avg_price, fill=elevator)) +
  geom_bar(stat = "identity", position = "dodge") + 
  ggtitle("Precio medio por distrito y ascensor") +
  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 30, hjust = 1)) + 
  labs(x = "Distrito", y = "Precio medio")
```

```{r}
mhp_train %>%
  group_by(district, garage) %>% 
  summarise(avg_price = mean(price)) %>%
  ggplot(aes(x=district, y=avg_price, fill=garage)) +
  geom_bar(stat = "identity", position = "dodge") + 
  ggtitle("Precio medio por distrito y garaje") +
  theme(plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 30, hjust = 1)) + 
  labs(x = "Distrito", y = "Precio medio")
```

## Transformación de variables cuantitativas

```{r}
plot_grid(
  
  ggplot(mhp_train, aes(x = m2, y = price)) +
  geom_point() +
  geom_smooth() +
  ggtitle('Relación entre el precio y los metros cuadrados'),
  
  ggplot(mhp_train, aes(x = rooms, y = price)) +
  geom_point() +
  geom_smooth() +
  ggtitle('Relación entre el precio y el múmero de habitaciones'),
  
  ggplot(mhp_train, aes(x = rooms, y = m2)) +
  geom_point() +
  geom_smooth() +
  ggtitle('Relación entre los metros cuadrados y el número de habitaciones'),
  
  nrow = 2
)
```

## Procesado de variables cualitativas

```{r}
mhp_train %>%
  group_by(house_type) %>%
  summarise(precio_medio = mean(price)) %>%
  arrange(precio_medio)
```

Para el posterior análisis transformamos la columna house_type, agrupando en "piso" (independientemente de la planta en la que esté), "casa" (casa o chalet) y "sotano".

```{r}
mhp_train <- mhp_train %>%
  mutate(tipo_casa = case_when(
    grepl("casa|chalet", house_type, ignore.case = TRUE) ~ "casa",
    grepl("\\bplanta\\s*-?1\\b|semi-?sotano|bajo|sotano", house_type, ignore.case = TRUE) ~ "sotano",
    TRUE ~ "piso"
  ))
mhp_train$tipo_casa <- as.factor(mhp_train$tipo_casa)
```

También creamos una columna con el precio medio por distrito en la que salen las variables caro, medio o barato en función del precio del distrito.

```{r}
mhp_train <- mhp_train %>%
  group_by(district) %>%
  mutate(precio_distrito = mean(price)) %>%
  ungroup()

# Calcular los percentiles
percentiles <- quantile(mhp_train$precio_distrito, probs = c(0, 1/3, 2/3, 1))

# Asignar etiquetas
mhp_train$precio_distrito <- cut(mhp_train$precio_distrito, breaks = percentiles, labels = c("barato", "medio", "caro"), include.lowest = TRUE)
```

Creamos nuestra variable target binaria

```{r}
mhp_train$precio_bin <- ifelse(mhp_train$price > median(mhp_train$price), "cara", "barata")
mhp_train$precio_bin = ifelse(mhp_train$precio_bin == "cara", 1, 0)
mhp_train$precio_bin = factor(mhp_train$precio_bin, levels = c(1,0))
```


Aplicamos los cambios también a test.

```{r}
# Categorizamos house_type
mhp_test <- mhp_test %>%
  mutate(tipo_casa = case_when(
    grepl("casa|chalet", house_type, ignore.case = TRUE) ~ "casa",
    grepl("\\bplanta\\s*-?1\\b|semi-?sotano|bajo|sotano", house_type, ignore.case = TRUE) ~ "sotano",
    TRUE ~ "piso"
  ))
mhp_test$tipo_casa <- as.factor(mhp_test$tipo_casa)

# Categorizamos los distritos
mhp_test <- mhp_test %>%
  group_by(district) %>%
  mutate(precio_distrito = mean(price)) %>%
  ungroup()

percentiles <- quantile(mhp_test$precio_distrito, probs = c(0, 1/3, 2/3, 1))

mhp_test$precio_distrito <- cut(mhp_test$precio_distrito, breaks = percentiles, labels = c("barato", "medio", "caro"), include.lowest = TRUE)

# Creamos variable target
mhp_test$precio_bin <- ifelse(mhp_test$price > median(mhp_test$price), "cara", "barata")
mhp_test$precio_bin = ifelse(mhp_test$precio_bin == "cara", 1, 0)
mhp_test$precio_bin = factor(mhp_test$precio_bin, levels = c(1,0))
```

# Modelo de regresión lineal

```{r}
lm_fit <- lm(price ~ m2+rooms+exterior+elevator+garage, data=mhp_train)
summary(lm_fit)
coef(lm_fit)
```

```{r}
residuals=lm_fit$residuals
autoplot(lm_fit)
```

# Conclusiones preliminares

```{r}
summary(mhp_train)
```





# Aprendizaje no supervisado

# Técnicas de reducción de la dimensionalidad

##PCA

Dividimos el dataset quedándonos solo con las columnas numéricas y descartando la columna precio puesto que será de alguna manera nuestra variable dependiente.

```{r}
train <- mhp_train[,c(3:7,10,11,12)]
```

Creamos 3 variables dummy de 3 variables categóricas de si o no.

```{r}
dummy_garaje <- model.matrix(~0 + garage,data = train)
dummy_exterior <- model.matrix(~0 + exterior, data = train)
dummy_ascensor <- model.matrix(~0 + elevator, data = train)
dummy_tipo_casa <- model.matrix(~0 + tipo_casa, data = train)
dummy_distrito <- model.matrix(~0 + precio_distrito, data = train)
```

```{r}
dummy_data <- cbind(train[, c("rooms", "m2")],dummy_exterior,dummy_garaje,dummy_ascensor,dummy_distrito,dummy_tipo_casa)
```

```{r}
prcomp(dummy_data)
```
Podemos observar que en la PC1 lleva un peso casi de 100 la variable m2. En PC2 pasa lo mismo con la variable rooms y en el resto de PC está algo más repartido.

```{r}
summary(prcomp(dummy_data))
```
Al hacer un summary de las variables vemos que la proporción de varianza explicada por la primera componente es de un 99%, es decir, que es la única relevante. Si nos fijamos vemos que la PC1 está explicada casi al 100% por los m2 y si nos fijamos en nuestra tabla vemos que los m2 tienen valores mucho más altos que el resto de variables. Por lo tanto lo que hacemos a continuación es un análisis pero escalando las variables.

```{r}
prcomp(dummy_data, scale = T)
```
En este caso, podemos observar que están mucho más repartidos los pesos en las componentes principales. 


```{r}
pca_result <- prcomp(dummy_data, center = TRUE, scale = TRUE)
summary(pca_result)
```
Observamos que con PC6 ya llegamos al 80% de la proporción de varianza explicada pero vemos algunos saltos interesantes. Para ver cuantas componentes explican el modelo hacemos la regla de codo.

```{r}
plot(pca_result,type = "l",
     main="Variance explained by PCA"
)
```
Al observar el gráfico vemos que la forma del codo sería en la 6,7 aunque no es un gráfico muy claro. 

```{r}
plot(pca_result, main = "Gráfico PCA")
```

# Aprendizaje supervisado

## GLM

```{r}
train_glm <- mhp_train[,c(3:7,10,11,12)]
test_glm <- mhp_test[,c(3:7,10,11,12)]
```

Escalamos las columnas de m2 y rooms.

```{r}
train_glm[,2:3]<- scale(train_glm[,2:3])
test_glm[,2:3]<- scale(test_glm[,2:3])
```


```{r}
glm_mhp = glm(formula = precio_bin ~ exterior + garage + elevator + rooms + precio_distrito + tipo_casa,
                 data = train_glm, 
                 family = binomial)
summary(glm_mhp)
```
En particular, las variables "garage", "elevator", "rooms", "precio_distrito_medio", "precio_distrito_caro" y "plantas bajas" tienen una relación significativa y positiva con la probabilidad de que la vivienda sea "cara", mientras que la variable "rooms" tiene una relación negativa con la probabilidad de que la vivienda sea "cara". Esto no tiene mucho sentido puesto que a más habitaciones más probable que una casa sea cara.
El modelo explica una cantidad significativa de la varianza en la variable respuesta, con un AIC de 4904.4.

```{r}
head(predict(glm_mhp))
```
```{r}
head(fitted(glm_mhp))
```

```{r}
predicciones_glm <- ifelse(test = glm_mhp$fitted.values > 0.5, yes = 1, no = 0)
matriz_confusion_glm <- table(glm_mhp$model$precio_bin, predicciones_glm,
                          dnn = c("observaciones", "predicciones"))
matriz_confusion_glm
```


```{r}
library(effects)
efectos <- allEffects(glm_mhp)
plot(efectos)
```


## KNN

Aplicamos k-means sólo para las variables numéricas. Utilizando la regla del codo vemos que que lo correcto sería coger un k = 4. 

```{r}
X = mhp_train[,c(4,5)]
set.seed(6)
wcss = vector()
for (i in 1:10){
  wcss[i] <- sum(kmeans(X, i)$withinss)
}
plot(1:10, wcss, type = 'b', main = "Método del codo",
     xlab = "Número de clusters (k)", ylab = "WCSS(k)")
```

Aplicamos el algoritmo con k = 3 y vemos el gráfico de clusters que nos crea con k-means.
```{r}
# Aplicar el algoritmo de k-means con k óptimo
library(cluster)
kmeans <- kmeans(X, 3, iter.max = 300, nstart = 10)
clusplot(X, 
         kmeans$cluster,
         lines = 0,
         shade = TRUE,
         color = TRUE,
         labels = 1,
         plotchar = FALSE,
         span = TRUE,
         main = "Clustering de casas",
         xlab = "habitaciones",
         ylab = "m2"
         )
```

## KNN

Intentamos ver is hay un número correcto de k-vecinos que podemos usar.

```{r}
library(class)
long = 15
accuracy = rep(0,long)
f1score = rep(0,long)
recall = rep(0,long)
precision = rep(0,long)
for (i in 1:long)
{
  prediccion_knn_cv =knn.cv(mhp_train[,c("exterior","rooms","m2","elevator", "garage")], 
                            k=i, cl=mhp_train$precio_bin)
  accuracy[i] = sum(prediccion_knn_cv == mhp_train$precio_bin) /nrow(mhp_train)
  recall[i] = sum(prediccion_knn_cv == mhp_train$precio_bin & mhp_train$precio_bin == TRUE) / sum(mhp_train$precio_bin == TRUE)
  precision[i] = sum(prediccion_knn_cv == mhp_train$precio_bin & prediccion_knn_cv == TRUE) / sum(prediccion_knn_cv == TRUE)
  f1score[i] = 2*precision[i]*recall[i]/(precision[i]+recall[i])
}
resultados_knn = as.data.frame(cbind(accuracy,f1score,precision,recall))
resultados_knn = resultados_knn %>% mutate(index=as.factor(seq(1:long)))

max(resultados_knn$f1score)
which.max(resultados_knn$f1score)


ggplot(data=resultados_knn,aes(x=index,y=accuracy)) + 
  geom_col(colour="cyan4",fill="cyan3")+
  ggtitle("Accuracy")


ggplot(data=resultados_knn,aes(x=index,y=f1score)) + 
  geom_col(colour="orange4",fill="orange3") +
  ggtitle("F1_score values")

```

Analizando el gráfico no observamos ninguna diferencia, así que cogemos 5 que es el tamaño por defecto que se suele coger.

```{r}
library(distances)
# En train
prediccion_knn5_train =knn.cv(mhp_train[,c("exterior","rooms","m2","elevator", "garage")], 
                              k=5, cl=mhp_train$precio_bin)
confusionMatrix(table(prediccion_knn5_train,mhp_train$precio_bin), positive= "1")

#En test
prediccion_knn5_test=knn(mhp_train[,c("exterior","rooms","m2","elevator", "garage")], mhp_test[,c("exterior","rooms","m2","elevator", "garage")],
                         k=5, cl=mhp_train$precio_bin)
confusionMatrix(table(prediccion_knn5_test,mhp_test$precio_bin), positive= "1")
```

Tras realizar diferentes pruebas quitando variables vemos que si quitamos la variable m2 nos dice que hay muchos empates y no saca nada. Sin embargo, quitando las otras variables varia muy poco el acierto en train y test.
Obteniendo más o menos un 84% de acierto creemos que nos puede servir para clasificar las nuevas casas que entrasen en el dataset, puesto que no hemos sido capaces de mejorar ese %.


## Decision Trees

A continuación hacemos el modelo de arbol de decisión. 

```{r}
library(rpart)
library(rpart.plot)
library(rattle)
arbol <- rpart(precio_bin ~ garage + elevator + rooms + tipo_casa + precio_distrito, data = mhp_train, control = rpart.control(minsplit = 1))
fancyRpartPlot(arbol, sub = "")
```
Calculamos el número de aciertos y nos sale bastante aceptable.

```{r}
tab1 = table(pred = predict(arbol, mhp_test, type = "class"),
obs = mhp_test$precio_bin)
ntest = nrow(mhp_test)
acierto1 = sum(diag(tab1))/ntest
acierto1
```

Para validar el modelo podemos usar las funciones printcp y plotcp. La función printcp nos da el número óptimo de podas basada en el valor cp. La poda se realiza para evitar overfitting sobre los datos. 
El valor de cp ha de ser tal que la tasa de error de validación cruzada sea mínima.

```{r}
printcp(arbol)
```
```{r}
arbol$cptable[which.min(arbol$cptable[, "xerror"]),
"CP"]
```


```{r}
plotcp(arbol)
```
Podamos el árbol como indica la función. 

```{r}
pruneTREE1 = prune(arbol, cp = arbol$cptable[which.min(arbol$cptable[,
"xerror"]), "CP"])
fancyRpartPlot(pruneTREE1, uniform = TRUE, main = "Pruned Classification Tree",
sub = "")
```

```{r}
pruneTREE2 = prune(arbol, cp = arbol$cptable[5, "CP"])
fancyRpartPlot(pruneTREE2, uniform = TRUE, main = "Pruned Classification Tree",
sub = "")
```

```{r}
tab2 = table(pred = predict(pruneTREE2, mhp_test, type = "class"),
obs = mhp_test$precio_bin)
acierto2 = sum(diag(tab2))/ntest
acierto2
```
Nos sale literalmente es mismo resultado.

Creamos la matriz de confusión. 

```{r}
prediccion_1 <- predict(arbol, newdata = mhp_train, type = "class")
```

```{r}
confusionMatrix(prediccion_1, mhp_train[["precio_bin"]])
```


## Random Forest

```{r}
library(randomForest)
# Nos quedamos con todas las variables menos barrio porque hay muchas categorias
classifier = randomForest(x = mhp_train[,c(2,3,4,5,6,7,9)],
                          y = mhp_train$precio_bin,
                          ntree = 10)
```

```{r}
# Predicción de los resultados con el conjunto de testing
y_pred = predict(classifier, newdata = mhp_test[,c(2,3,4,5,6,7,9)])
```


```{r}
# Crear la matriz de confusión
#cm = table(mhp_test[,10], y_pred)
```


## SVM

# Ajuste de hiperparámetros del modelo

# Evaluación y comparación de modelos

# Elección punto de corte

# Redes Bayasianas y/o GAM